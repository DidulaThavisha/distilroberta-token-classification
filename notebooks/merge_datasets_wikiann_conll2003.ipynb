{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "general-service",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (1.5.0.dev0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-1.6.2-py3-none-any.whl (221 kB)\n",
      "\u001b[K     |████████████████████████████████| 221 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: multiprocess in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (0.70.11.1)\n",
      "Requirement already satisfied: fsspec in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (0.8.7)\n",
      "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (4.49.0)\n",
      "Requirement already satisfied: dill in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (0.3.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: packaging in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (20.9)\n",
      "Requirement already satisfied: xxhash in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (2.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (1.19.5)\n",
      "Requirement already satisfied: pyarrow>=1.0.0<4.0.0 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in /Users/philipp/Projects/huggingface/huggingface_hub/src (from datasets) (0.0.8)\n",
      "Requirement already satisfied: pandas in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (1.2.3)\n",
      "Requirement already satisfied: filelock in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Installing collected packages: datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 1.5.0.dev0\n",
      "    Uninstalling datasets-1.5.0.dev0:\n",
      "      Successfully uninstalled datasets-1.5.0.dev0\n",
      "Successfully installed datasets-1.6.2\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "royal-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset,concatenate_datasets, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intensive-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_column = [\"tokens\",\"ner_tags\"]\n",
    "split_list = [\"train\",\"validation\",\"test\"]\n",
    "\n",
    "def remove_columns_from_dataset_dict(dataset_dict,feature_columns):\n",
    "    assert sorted(split_list) == sorted(list(dataset_dict.keys())), \"Dataset is not containing all splits for train,test,val\"\n",
    "    for split in split_list:\n",
    "        remove_column_list = [col for col in list(dataset_dict[split].features) if col not in feature_column ]\n",
    "        dataset_dict[split] = dataset_dict[split].remove_columns(remove_column_list)\n",
    "    return dataset_dict\n",
    "\n",
    "\n",
    "def merging_all_splits_from_dataset_dict(dataset1,dataset2):\n",
    "    for split in split_list:\n",
    "        assert dataset1[split].features.type == dataset2[split].features.type\n",
    "        dataset1[split] = concatenate_datasets([dataset1[split],dataset2[split]])\n",
    "    return dataset1    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-values",
   "metadata": {},
   "source": [
    "# Preprocessing `wikiann`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "another-mortgage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bd8239bf074588b5b2a92fb41952b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=3948.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1014e3b5e0a14c2e8ebcbf1cf0611bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=12594.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikiann (/Users/philipp/.cache/huggingface/datasets/wikiann/en/1.1.0/c0a0280cc1c835e2bb7db29f43ef89c8ea30e145b78c1ba2746d709fae3da112)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wikiann= load_dataset(\"wikiann\",\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "military-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_selected_validation_wikiann = wikiann[\"validation\"].train_test_split(test_size=0.5)\n",
    "additional_selected_test_wikiann = wikiann[\"test\"].train_test_split(test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "military-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert wikiann[\"train\"].features.type == additional_selected_validation_wikiann[\"train\"].features.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "verbal-neighbor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wikiann[\"train\"] = concatenate_datasets([additional_selected_test_wikiann[\"train\"],wikiann[\"train\"]])\n",
    "wikiann[\"validation\"] = additional_selected_validation_wikiann[\"test\"]\n",
    "wikiann[\"test\"] = additional_selected_test_wikiann[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "continuous-latter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wikiann_cleaned = remove_columns_from_dataset_dict(wikiann,feature_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deluxe-tomorrow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikiann_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "collectible-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiann_cleaned.save_to_disk(\"../data/wikiann\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-minute",
   "metadata": {},
   "source": [
    "# Preprocessing `conll2003`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "duplicate-perfume",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834cad94f7344904af84b35adf53b458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2603.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4c22f257d742eeab9ae4ac210aaf2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1781.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (/Users/philipp/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "conll = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "global-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "conll_cleaned = remove_columns_from_dataset_dict(conll,feature_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "handy-processor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "automatic-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "conll_cleaned.save_to_disk(\"../data/conll\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-judges",
   "metadata": {},
   "source": [
    "# Merging the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "conservative-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_conll = load_from_disk(\"../data/conll\")\n",
    "wikiann_cleaned = load_from_disk(\"../data/conll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "brutal-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = merging_all_splits_from_dataset_dict(conll_cleaned,wikiann_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-surveillance",
   "metadata": {},
   "source": [
    "# Filter `ner_tags` to 3 or 4 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "forced-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_label_to_zero(example):\n",
    "    example[\"ner_tags\"] = [0 if label==7 or label==8 else label for label in example[\"ner_tags\"]]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "romantic-lodge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b4487eae904df281b940ee0caf848b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "conll_cleaned[\"train\"] = conll_cleaned[\"train\"].map(change_label_to_zero,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "engaging-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "english-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature = datasets.Sequence(\n",
    "                        datasets.features.ClassLabel(\n",
    "                            names=[\n",
    "                                \"O\",\n",
    "                                \"B-PER\",\n",
    "                                \"I-PER\",\n",
    "                                \"B-ORG\",\n",
    "                                \"I-ORG\",\n",
    "                                \"B-LOC\",\n",
    "                                \"I-LOC\",\n",
    "                            ]\n",
    "                        )\n",
    "                    ),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "pretty-bouquet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conll_cleaned[\"train\"].features[\"ner_tags\"] =new_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "warming-australia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequence(feature=ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], names_file=None, id=None), length=-1, id=None),)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll_cleaned[\"train\"].features[\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-laugh",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "joined-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent = os.path.dirname(os.getcwd())\n",
    "\n",
    "sys.path.insert(0,f'{parent}/src/training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alike-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_utils import merge_datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "piano-establishment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikiann (/Users/philipp/.cache/huggingface/datasets/wikiann/en/1.1.0/c0a0280cc1c835e2bb7db29f43ef89c8ea30e145b78c1ba2746d709fae3da112)\n",
      "Reusing dataset conll2003 (/Users/philipp/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76b0190cca94c5cb1ae290fa4e00582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0140a5521f6e4bcc8915347a9e5fc119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22ad6af61d4456fa4769554c2882c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wikiann= load_dataset(\"wikiann\",\"en\")\n",
    "conll = load_dataset(\"conll2003\")\n",
    "\n",
    "ds = merge_datasets(conll,wikiann,class_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wrapped-chile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ner_tags', 'tokens'],\n",
       "        num_rows: 28082\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['ner_tags', 'tokens'],\n",
       "        num_rows: 6500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ner_tags', 'tokens'],\n",
       "        num_rows: 6906\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fatty-measure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequence(feature=ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], names_file=None, id=None), length=-1, id=None),)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"].features[\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-portable",
   "metadata": {},
   "source": [
    "# load_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "defined-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent = os.path.dirname(os.getcwd())\n",
    "\n",
    "sys.path.insert(0,f'{parent}/src/training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "detailed-crawford",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_utils import load_ner_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "better-links",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (/Users/philipp/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6)\n",
      "Reusing dataset wikiann (/Users/philipp/.cache/huggingface/datasets/wikiann/en/1.1.0/c0a0280cc1c835e2bb7db29f43ef89c8ea30e145b78c1ba2746d709fae3da112)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18be2bc143764e238d130e3af0df189d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c477075219f34bb6a28a51696f2e2e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c24969d67e417eb57aa7e803dc699d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0], 'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d436f0907d95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_to_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_ner_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wikiann-conll2003'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/personal/models/distilroberta-token-classification/src/training/preprocess_utils.py\u001b[0m in \u001b[0;36mload_ner_dataset\u001b[0;34m(name, class_num)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mconll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"conll2003\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mwikiann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wikiann\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"en\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwikiann\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Define either conll, wikiann or all as name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/personal/models/distilroberta-token-classification/src/training/preprocess_utils.py\u001b[0m in \u001b[0;36mmerge_datasets\u001b[0;34m(conll, wikiann, class_num)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;36m7\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ner_tags\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0mwikiann_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/wikiann\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mconll_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/conll\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datasets, num_labels, label_to_id, label_list = load_ner_dataset('wikiann-conll2003',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "circular-ready",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0], 'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7bad543bd881>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;36m7\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ner_tags\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "for d in datasets[\"train\"]:\n",
    "    if 7 in d[\"ner_tags\"]:\n",
    "        print(d)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-potential",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
